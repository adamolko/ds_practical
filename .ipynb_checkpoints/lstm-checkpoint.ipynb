{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses Recurrent Neural Network with Long-Short-Term Memory units.<br>\n",
    "We perform 70/30 train/test split on the data. Fit the model on the train data and then predict the outcome for all the test observations at once.<br>\n",
    "The breakpoint detection is done for every test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for calculating *Symmetric Mean Absolute Percentage Error*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(predictions, actual):\n",
    "    difference = np.abs(predictions-actual)\n",
    "    summation = np.abs(actual)+np.abs(predictions)\n",
    "    error = np.mean(difference/summation)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since now we can't use *ada_preprocessing()* to extract lagged values and concept, because it can potentially mess up breakpoint detection, we need separate function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_preprocessing(values):\n",
    "    #receives the list of values up until and including the test point\n",
    "    \n",
    "    columns = [\"t\", \"t-1\", \"t-2\", \"t-3\", \"t-4\", \"t-5\"]\n",
    "    data = [values[-1], values[-2], values[-3], values[-4], values[-5], values[-6]]\n",
    "    \n",
    "    df = pd.DataFrame(columns=columns, data=[data])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_preprocessing(train, test):\n",
    "    train_X, train_y = train.iloc[:,1:], train.iloc[:,0]\n",
    "    test_X, test_y = test.iloc[:,1:], test.iloc[:,0]\n",
    "    \n",
    "    #separate both train and test sets into inputs and auxiliary variables\n",
    "    train_X_input = train_X.loc[:,\"t-1\":\"t-5\"]\n",
    "    test_X_input = test_X.loc[:,\"t-1\":\"t-5\"]\n",
    "    \n",
    "    #now also need to reshape X_input and X_aux\n",
    "    X_arrays = np.asarray(train_X_input)\n",
    "    train_X_input = np.hstack(X_arrays).reshape(train_X_input.shape[0], 1, train_X_input.shape[1])\n",
    "    \n",
    "    #need to do the same for test set\n",
    "    X_arrays = np.asarray(test_X_input)\n",
    "    test_X_input = np.hstack(X_arrays).reshape(test_X_input.shape[0], 1, test_X_input.shape[1])\n",
    "    \n",
    "    return train_X_input, test_X_input, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(train):\n",
    "    # reshape training into [samples, timesteps, features]\n",
    "    X, y = train.iloc[:, 1:], train.iloc[:, 0]\n",
    "    \n",
    "    #cannot reshape datafame\n",
    "    X_arrays = np.asarray(X)\n",
    "    X = np.hstack(X_arrays).reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "    #build model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(X.shape[1], X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    es = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',  patience=5, verbose=0, mode='auto',\n",
    "    )\n",
    "    \n",
    "    # fit network\n",
    "    model.fit(X, y, epochs = 1000, batch_size = 100, verbose = 0, callbacks=[es], shuffle = False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_names = [\"linear1_abrupt\", \"linear2_abrupt\", \"linear3_abrupt\",\n",
    "                \"nonlinear1_abrupt\", \"nonlinear2_abrupt\", \"nonlinear3_abrupt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_dict = {}\n",
    "\n",
    "for name in [list_of_names[0]]:\n",
    "    file_path = \"data/\"+name+\"_series\"\n",
    "    data = pd.read_csv(file_path).iloc[:,0].to_list()\n",
    "\n",
    "    #70/30 train/test split\n",
    "    split = int(0.7*len(data))\n",
    "    train, test = data[:split], data[split:]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    #need to perform the first step outside of the loop,\n",
    "    #because we don't want to retrain our model each time\n",
    "    \n",
    "    #get breakpoints for train dataset\n",
    "    history = functions.ada_preprocessing(train)\n",
    "    history.drop([\"transition\", \"steps_to_bkp\", \"steps_since_bkp\"], axis = 1, inplace = True)\n",
    "\n",
    "    #get the dataframe for new test observation\n",
    "    train.append(test[0])\n",
    "    test_row = manual_preprocessing(train, history.tail(1))\n",
    "    X = test_row.loc[:,\"t-1\":\"t-5\"]\n",
    "    X_arrays = np.asarray(X)\n",
    "    test_X = np.hstack(X_arrays).reshape(X.shape[0], 1, X.shape[1])\n",
    "    \n",
    "    #fit the model just once\n",
    "    model = fit_lstm(history)\n",
    "    \n",
    "    #get predictions for new test observation\n",
    "    prediction = model.predict(test_X)\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "        \n",
    "    #we've got the first prediction, so now start from 1\n",
    "    for i in range(1, len(test)):\n",
    "        #get breakpoints for train dataset\n",
    "        history = functions.ada_preprocessing(train)\n",
    "        \n",
    "        history.drop([\"transition\", \"steps_to_bkp\", \"steps_since_bkp\"], axis = 1, inplace = True)\n",
    "        \n",
    "        #get the dataframe for new test observation\n",
    "        train.append(test[i])\n",
    "        test_row = manual_preprocessing(train, history.tail(1))\n",
    "        \n",
    "        X = test_row.loc[:,\"t-1\":\"t-5\"]\n",
    "        X_arrays = np.asarray(X)\n",
    "        test_X = np.hstack(X_arrays).reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "        #get predictions for new test observation\n",
    "        prediction = model.predict(test_X)\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        \n",
    "    end = time.perf_counter()\n",
    "    print(\"Time spent: {:.2f}h\".format((end-start)/3600))\n",
    "\n",
    "    error = smape(np.asarray(predictions), np.asarray(test))\n",
    "    smape_dict[name] = error\n",
    "    print(\"SMAPE: {:.4f}\".format(error))\n",
    "    \n",
    "    plt.plot(test, label = \"expected\", color = \"black\")\n",
    "    plt.plot(np.asarray(predictions).reshape([-1,1]), label = \"predicted\", color = \"red\")\n",
    "    plt.title(name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
