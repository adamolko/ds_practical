{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functions\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(predictions, actual):\n",
    "    difference = np.abs(predictions-actual)\n",
    "    summation = np.abs(actual)+np.abs(predictions)\n",
    "    error = np.mean(difference/summation)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "file_path = \"data/linear1_abrupt\"\n",
    "data = pd.read_csv(file_path).iloc[:,0].to_list()\n",
    "\n",
    "#note: i only use this to get the lagged values, the concepts and others are dropped subsequently\n",
    "data = functions.ada_preprocessing(data)\n",
    "data = data.loc[:, \"t\":\"t-5\"]\n",
    "\n",
    "#train/test split\n",
    "n = len(data)\n",
    "train, test = data[:int(0.7*n)], data[int(0.7*n):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(n_neuron, n_epoch, n_batch, optimizer):\n",
    "    # reshape training into [samples, timesteps, features]\n",
    "    X, y = train.iloc[:, 1:], train.iloc[:, 0]\n",
    "    #cannot reshape datafame\n",
    "    X_arrays = np.asarray(X)\n",
    "    X = np.hstack(X_arrays).reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "    #build model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neuron, input_shape=(X.shape[1], X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    \n",
    "    es = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',  patience=5, verbose=0, mode='auto',\n",
    "    )\n",
    "    \n",
    "    # fit network\n",
    "    model.fit(X, y, epochs = n_epoch, batch_size = n_batch, verbose = 0, callbacks=[es], shuffle = False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data\n",
    "X_test, y_test = test.loc[:,\"t-1\":\"t-5\"], test.loc[:,\"t\"]\n",
    "X_arrays = np.asarray(X_test)\n",
    "test_X = np.hstack(X_arrays).reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "optimizers = [\"adam\", \"adamax\", \"rmsprop\"]\n",
    "n_epochs = np.arange(10,1060, 50)\n",
    "n_batches = np.arange(1, 110, 10)\n",
    "n_neurons = [4,8,16,32,64]\n",
    "\n",
    "min_error = 100\n",
    "params = {}\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for n_batch in n_batches:\n",
    "        for n_neuron in n_neurons:\n",
    "            for n_epoch in n_epochs:\n",
    "                start = time.perf_counter()\n",
    "                #fit the model just once\n",
    "                model = fit_lstm(n_neuron, n_epoch, n_batch, optimizer)\n",
    "\n",
    "                #get predictions for new test observation\n",
    "                predictions = model.predict(test_X)\n",
    "                end = time.perf_counter()\n",
    "#                 print(\"Time wasted: {:.2f}h\".format((end-start)/3600))\n",
    "                error = smape(np.asarray(predictions), np.asarray(y_test))\n",
    "                if error<min_error:\n",
    "                    min_error\n",
    "                    params[\"optimizer\"] = optimizer\n",
    "                    params[\"n_batch\"] = n_batch\n",
    "                    params[\"n_neuron\"] = n_neuron\n",
    "                    params[\"n_epoch\"] = n_epoch\n",
    "\n",
    "print(min_error)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
