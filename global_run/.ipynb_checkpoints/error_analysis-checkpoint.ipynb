{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_names = [\"linear1_abrupt\", \"linear2_abrupt\", \"linear3_abrupt\", \n",
    "                 \"nonlinear1_abrupt\", \"nonlinear2_abrupt\", \"nonlinear3_abrupt\"]\n",
    "list_of_algorithms = [\"baseline\", \"xgboost/retrain\", \"xgboost/redefine\", \"xgboost/discard\",\n",
    "                     \"lstm/oneshot\", \"lstm/discard\", \"cond_rnn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "{'linear1_abrupt': 0.29417738956073974, 'linear2_abrupt': 0.26736086978536455, 'linear3_abrupt': 0.5546428405524981, 'nonlinear1_abrupt': 0.7163350180654369, 'nonlinear2_abrupt': 0.2872563270603232, 'nonlinear3_abrupt': 0.5628715117039894}\n",
      "xgboost/retrain\n",
      "{'linear1_abrupt': 0.08614086622975599, 'linear2_abrupt': 0.03723613974701801, 'linear3_abrupt': 0.1470272044561834, 'nonlinear1_abrupt': 0.6922672571438223, 'nonlinear2_abrupt': 0.11155178657142906, 'nonlinear3_abrupt': 0.297090939853725}\n",
      "xgboost/redefine\n",
      "{'linear1_abrupt': 0.07987732488202354, 'linear2_abrupt': 0.052717178894369776, 'linear3_abrupt': 0.15617096836316124, 'nonlinear1_abrupt': 0.6696108635180984, 'nonlinear2_abrupt': 0.12165076399080861, 'nonlinear3_abrupt': 0.2928700209891004}\n",
      "xgboost/discard\n",
      "{'linear1_abrupt': 0.08275492512716864, 'linear2_abrupt': 0.053022097903144765, 'linear3_abrupt': 0.15532870622022757, 'nonlinear1_abrupt': 0.6933843399992626, 'nonlinear2_abrupt': 0.1269157744439974, 'nonlinear3_abrupt': 0.29157017517444134}\n",
      "lstm/oneshot\n",
      "{'linear1_abrupt': 0.4281682093057389, 'linear2_abrupt': 0.2989226863574747, 'linear3_abrupt': 0.6083191344317185, 'nonlinear1_abrupt': 0.7478590180407769, 'nonlinear2_abrupt': 0.3653337161750297, 'nonlinear3_abrupt': 0.5518215282862371}\n",
      "lstm/discard\n",
      "{'linear1_abrupt': 0.47316638429920777, 'linear2_abrupt': 0.4471354523433145, 'linear3_abrupt': 0.6028431319259516, 'nonlinear1_abrupt': 0.7167827442658828, 'nonlinear2_abrupt': 0.42619686745089425, 'nonlinear3_abrupt': 0.5507037484889784}\n",
      "cond_rnn\n",
      "{'linear1_abrupt': 0.4043020984834606, 'linear2_abrupt': 0.3093855551987481, 'linear3_abrupt': 0.609645944529866, 'nonlinear1_abrupt': 0.7688133839371236, 'nonlinear2_abrupt': 0.30317616454206475, 'nonlinear3_abrupt': 0.541613555486716}\n"
     ]
    }
   ],
   "source": [
    "# for every algorithms\n",
    "for algorithm in list_of_algorithms:\n",
    "    print(algorithm)\n",
    "    # create dictionary to keep track of the errors for particular algorithm\n",
    "    errors = {}\n",
    "    # for every type of time series\n",
    "    for name in list_of_names:\n",
    "        # keep track of how many iterations for one type were done\n",
    "        count = 0\n",
    "        total_error = 0\n",
    "        # extract the errors for particular time series\n",
    "        r1 = re.compile('error[0-9]'+name+'.txt')\n",
    "        # cd into necessary folder\n",
    "        for root, dirs, files in os.walk(\"results/\"+algorithm+\"/errors\"):\n",
    "            for file in files:\n",
    "                if r1.match(file):\n",
    "                    # read all the files related to particular type of time series\n",
    "                    with open(os.path.join(root, file), 'r') as f:\n",
    "                        text = f.read()\n",
    "                        # add to total error\n",
    "                        total_error += float(text.split(\",\")[1])\n",
    "                        # increase the iteration counter\n",
    "                        count+= 1\n",
    "        errors[name] = total_error/count\n",
    "    print(errors)\n",
    "    #for every algorithm, save the mean errors\n",
    "    dict_path = \"results/\"+algorithm+\"/errors/mean_errors.txt\"\n",
    "    with open(dict_path, 'w') as file:\n",
    "        for key in errors.keys():\n",
    "            file.write(\"%s,%s\\n\"%(key,errors[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
